使用hadoop实现KPI统计
一、架构设计
1.日志是由业务系统产生，可以设置web服务器每天产生一个新的目录，
目录下产生多个日志文件，每个文件64M
2.设置系统定时器CRON，在夜间0点后，向HDFS导入昨天的文件。
3.完成导入后，设置系统定时器，启动MapReduce程序，提取并计算统计指标。
4.完成计算后，设置系统定时器，从HDFS导出统计指标数据到数据库，方便以后查询。
二、并行算法设计
1.PV(pageview):页面访问量统计
map过程{key:$request,value:1}
reduce过程{key:$request,value:求和(sum)}
2.IP页面独立IP的访问量统计
map过程{key:$request,value:$remote_addr}
reduce过程{key:$request,value:去重再求和(sum(unique))}
3.Time:用户每小时PV统计
map过程{key:$time_local,value:1}
reduce过程{key:$time_local,value:求和(sum)}
4.Source:用户来源域名的统计
map过程{key:$http_referer,value:1}
reduce过程{key:$http_referer,value:求和(sum)}
5.Browser:用户的访问设备统计
map过程{key:$http_user_agent,value:1}
reduce过程{key:$http_user_agent,value:求和(sum)}



